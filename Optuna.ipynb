{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b38973-3f5f-42f7-b6ec-6625037a0e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgbo\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c335c2-803e-4239-a30e-40519ee681a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  price  \n",
       "0        -122.23  4.526  \n",
       "1        -122.22  3.585  \n",
       "2        -122.24  3.521  \n",
       "3        -122.25  3.413  \n",
       "4        -122.25  3.422  \n",
       "...          ...    ...  \n",
       "20635    -121.09  0.781  \n",
       "20636    -121.21  0.771  \n",
       "20637    -121.22  0.923  \n",
       "20638    -121.32  0.847  \n",
       "20639    -121.24  0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "# 例としてscikit-learnで提供されているカリフォルニアの住宅価格データを用いる\n",
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "X = data[\"data\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "# 見やすいようにDataFrameにする\n",
    "df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))),\n",
    "                  columns=data.feature_names+[\"price\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3900c-2b5b-4f38-8f8f-fae96a865223",
   "metadata": {},
   "source": [
    "## XGBOOSTをOptunaで最適化する  \n",
    "Optunaはベイズ最適化を用いてパラメータ最適化をするライブラリです．ランダムサーチやグリッドサーチよりも効率的にパラメータ最適化を行うことができます．\n",
    "\n",
    "最適化の際には関数として一連の処理を定義しておく必要があります．\n",
    "\n",
    "1. 最適化したいパラメータと，パラメータの取りうる値を定義します．パラメータの取りうる値はtrial.suggest_intやtrial.suggest_loguniformなどで指定します．  \n",
    "2. 設定したパラメータをモデルに渡してモデルの学習と，評価を行います．  \n",
    "3. 最小化，もしくは最大化したい値を関数の返り値として設定します．\n",
    "\n",
    "最適化するパラメータ，最小化，もしくは最大化する目的関数を自由に設定することができるため，基本的にどのようなモデルにも適用できる，目的関数も自分で実装して最適化することができます．また今回は最適化対象のパラメータが整数や小数でしたが，質量変数を指定する場合はsuggest_categoricalを用いるなどできます．より詳細には[公式ページ](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html)がありますのでパラメータによって使用するものを変えるようにしてください．  \n",
    "\n",
    "その後optuna.create_studyでインスタンスを作成します．その際の引き数に\"direction\"というものがあり，\"maximize\"を指定することで目的関数を最大化するように，\"minimize\"を指定することで最小化するようにパラメータを最適化するようにします．\n",
    "\n",
    "インスタンスのoptimizeメソッドに最適化するための関数，イテレータ数を指定することで最適化が始まります．timeoutを指定することで一定時間がかかると処理を中断するように設定できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5ef451-48ab-4112-84e8-9359ea5a0ab9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-30 09:13:55,575]\u001b[0m A new study created in memory with name: no-name-e01a8900-c95a-4b97-85ba-a6f5b3533c2d\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:13:57,357]\u001b[0m Trial 0 finished with value: 0.4716889859796756 and parameters: {'n_estimators': 340, 'max_depth': 7, 'max_leaves': 12, 'learning_rate': 0.03399685126151244}. Best is trial 0 with value: 0.4716889859796756.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:13:58,521]\u001b[0m Trial 1 finished with value: 1.6117138939589892 and parameters: {'n_estimators': 152, 'max_depth': 9, 'max_leaves': 3, 'learning_rate': 0.0014762134546744993}. Best is trial 0 with value: 0.4716889859796756.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:13:59,880]\u001b[0m Trial 2 finished with value: 0.4943095012550664 and parameters: {'n_estimators': 298, 'max_depth': 6, 'max_leaves': 16, 'learning_rate': 0.021914669583863077}. Best is trial 0 with value: 0.4716889859796756.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:01,548]\u001b[0m Trial 3 finished with value: 1.653294909983414 and parameters: {'n_estimators': 310, 'max_depth': 7, 'max_leaves': 27, 'learning_rate': 0.0006356903636955752}. Best is trial 0 with value: 0.4716889859796756.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:04,591]\u001b[0m Trial 4 finished with value: 0.46965139992500093 and parameters: {'n_estimators': 396, 'max_depth': 9, 'max_leaves': 3, 'learning_rate': 0.03854418038895465}. Best is trial 4 with value: 0.46965139992500093.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:05,037]\u001b[0m Trial 5 finished with value: 1.229027572952617 and parameters: {'n_estimators': 112, 'max_depth': 5, 'max_leaves': 9, 'learning_rate': 0.005289035080772511}. Best is trial 4 with value: 0.46965139992500093.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:05,345]\u001b[0m Trial 6 finished with value: 0.5202808082912601 and parameters: {'n_estimators': 113, 'max_depth': 4, 'max_leaves': 27, 'learning_rate': 0.06814220935506365}. Best is trial 4 with value: 0.46965139992500093.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:07,425]\u001b[0m Trial 7 finished with value: 0.4671739221432632 and parameters: {'n_estimators': 290, 'max_depth': 9, 'max_leaves': 12, 'learning_rate': 0.05285868989188462}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:09,877]\u001b[0m Trial 8 finished with value: 0.47931322265726567 and parameters: {'n_estimators': 449, 'max_depth': 7, 'max_leaves': 14, 'learning_rate': 0.018148841463259204}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:11,439]\u001b[0m Trial 9 finished with value: 0.5668148370282083 and parameters: {'n_estimators': 224, 'max_depth': 8, 'max_leaves': 29, 'learning_rate': 0.010515576508208604}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:13,629]\u001b[0m Trial 10 finished with value: 1.9064417165992293 and parameters: {'n_estimators': 223, 'max_depth': 10, 'max_leaves': 20, 'learning_rate': 0.00013654194792068344}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:16,924]\u001b[0m Trial 11 finished with value: 0.47594419643524905 and parameters: {'n_estimators': 430, 'max_depth': 10, 'max_leaves': 1, 'learning_rate': 0.09996169627995091}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:19,548]\u001b[0m Trial 12 finished with value: 0.6494157476811554 and parameters: {'n_estimators': 341, 'max_depth': 9, 'max_leaves': 7, 'learning_rate': 0.00502563045631796}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:22,459]\u001b[0m Trial 13 finished with value: 0.4679413324691232 and parameters: {'n_estimators': 405, 'max_depth': 9, 'max_leaves': 6, 'learning_rate': 0.05299500850228133}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:23,381]\u001b[0m Trial 14 finished with value: 1.1203818002070678 and parameters: {'n_estimators': 481, 'max_depth': 3, 'max_leaves': 20, 'learning_rate': 0.001651505899791136}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:25,755]\u001b[0m Trial 15 finished with value: 0.4984054350659987 and parameters: {'n_estimators': 387, 'max_depth': 8, 'max_leaves': 8, 'learning_rate': 0.010755630049006903}. Best is trial 7 with value: 0.4671739221432632.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:27,105]\u001b[0m Trial 16 finished with value: 0.46433805111795423 and parameters: {'n_estimators': 230, 'max_depth': 8, 'max_leaves': 18, 'learning_rate': 0.062790703980626}. Best is trial 16 with value: 0.46433805111795423.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:28,680]\u001b[0m Trial 17 finished with value: 1.9175836041606946 and parameters: {'n_estimators': 238, 'max_depth': 8, 'max_leaves': 20, 'learning_rate': 0.00010118501168418774}. Best is trial 16 with value: 0.46433805111795423.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:29,799]\u001b[0m Trial 18 finished with value: 0.4634409527783798 and parameters: {'n_estimators': 267, 'max_depth': 6, 'max_leaves': 17, 'learning_rate': 0.09518874548034575}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:30,496]\u001b[0m Trial 19 finished with value: 0.4789733970443035 and parameters: {'n_estimators': 179, 'max_depth': 5, 'max_leaves': 24, 'learning_rate': 0.0881716632537151}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:31,853]\u001b[0m Trial 20 finished with value: 0.5069893857436905 and parameters: {'n_estimators': 268, 'max_depth': 6, 'max_leaves': 18, 'learning_rate': 0.018391697707087977}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:33,740]\u001b[0m Trial 21 finished with value: 0.4703168681416816 and parameters: {'n_estimators': 262, 'max_depth': 8, 'max_leaves': 12, 'learning_rate': 0.03609567759842981}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:34,463]\u001b[0m Trial 22 finished with value: 0.4781715017006614 and parameters: {'n_estimators': 190, 'max_depth': 5, 'max_leaves': 16, 'learning_rate': 0.097160218971157}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:35,686]\u001b[0m Trial 23 finished with value: 0.46915067726619786 and parameters: {'n_estimators': 294, 'max_depth': 6, 'max_leaves': 23, 'learning_rate': 0.051781412936483966}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:38,883]\u001b[0m Trial 24 finished with value: 0.5100348584132852 and parameters: {'n_estimators': 330, 'max_depth': 10, 'max_leaves': 12, 'learning_rate': 0.009920412158058743}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:40,314]\u001b[0m Trial 25 finished with value: 0.48123683562182673 and parameters: {'n_estimators': 261, 'max_depth': 7, 'max_leaves': 14, 'learning_rate': 0.02557318937365838}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:41,451]\u001b[0m Trial 26 finished with value: 0.4690398507190544 and parameters: {'n_estimators': 186, 'max_depth': 8, 'max_leaves': 18, 'learning_rate': 0.06020391329867557}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:44,162]\u001b[0m Trial 27 finished with value: 1.6743906439610736 and parameters: {'n_estimators': 370, 'max_depth': 9, 'max_leaves': 10, 'learning_rate': 0.00048567781197473154}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:44,806]\u001b[0m Trial 28 finished with value: 1.0343100091460031 and parameters: {'n_estimators': 153, 'max_depth': 6, 'max_leaves': 23, 'learning_rate': 0.005446606404796733}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:14:46,661]\u001b[0m Trial 29 finished with value: 0.4703081528332039 and parameters: {'n_estimators': 355, 'max_depth': 7, 'max_leaves': 11, 'learning_rate': 0.03181829810171739}. Best is trial 18 with value: 0.4634409527783798.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # データを訓練用と検証用に分割する\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=6174)\n",
    "\n",
    "    # 最適化したいパラメータと，パラメータがとる値の範囲を指定する\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 1, 30),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-1),\n",
    "    }\n",
    "\n",
    "    # モデルの訓練\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(train_X, train_y)\n",
    "\n",
    "    # モデルの評価\n",
    "    pred = model.predict(val_X)\n",
    "    score = mse(val_y, pred, squared=False)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")  # maximizeにすると最大化問題になる\n",
    "study.optimize(objective, 30, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b426362-56d1-44f1-8c48-03391e06e8d7",
   "metadata": {},
   "source": [
    "パラメータの最適化が終わった後は，最も性能が良かったパラメータと，その時のスコアを表示することができます．studyのbest_params属性とbest_value属性にアクセスすることでこれらの値を得ることができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cd427d-37c4-47ae-ada0-a576fc44af63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 267,\n",
       " 'max_depth': 6,\n",
       " 'max_leaves': 17,\n",
       " 'learning_rate': 0.09518874548034575}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3038dceb-b2bd-42b3-b50d-f684b58cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4634409527783798"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d0ca1-375d-4b28-a971-3b5c63caf3b8",
   "metadata": {},
   "source": [
    "簡単な使用方法は以上となります．最適化するパラメータや，評価手法（ホールドアウトを交差検証に変えるなど），目的関数を自由に変えることができるので基本的にどのようなタスク，モデルでも用いることができます．  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ba7de-b55f-43c3-a4ba-b4d5a6e0e7b1",
   "metadata": {},
   "source": [
    "## PyTorchのモデルを最適化してみる  \n",
    "あまり使用されているところ見たことがないのですが，PyTorchのモデルの隠れ層のニューロン数やドロップアウトの割合も最適化できます．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6accbd62-0e6e-456e-87f9-50c864b9ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "# DataFrameから使用するデータを抽出し，1つずつ変えずだけのもの\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, features, target):\n",
    "        X = df[features].values\n",
    "        y = df[target].values\n",
    "\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfe8100-14a4-4e41-89ed-6eb0d23e5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単純な3層ニューラルネット\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dr=0.3, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dr = nn.Dropout(p=dr)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.activation(self.hidden(x))\n",
    "        dr_h = self.dr(h)\n",
    "        y = self.out(dr_h)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "# データの分割\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=6174)\n",
    "features = df.columns[:-1]\n",
    "target = df.columns[-1]\n",
    "\n",
    "# ニューラルネット用にスケーリングする\n",
    "sc = StandardScaler()\n",
    "train_df[features] = sc.fit_transform(train_df[features])\n",
    "val_df[features] = sc.transform(val_df[features])\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataset = TestDataset(train_df, features, target)\n",
    "val_dataset = TestDataset(val_df, features, target)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# モデル，損失関数，最適化手法の定義\n",
    "model = TestModel(len(features), 32, 1).to(\"cuda\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optimizers.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# 1イテレーション分の訓練\n",
    "def train(batch_X, batch_y):\n",
    "    model.train()\n",
    "    batch_X, batch_y = batch_X.to(\"cuda\"), batch_y.to(\"cuda\")\n",
    "    pred = model(batch_X)\n",
    "\n",
    "    loss = torch.sqrt(criterion(pred, batch_y))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 1イテレーション分の評価\n",
    "def validation(batch_X, batch_y):\n",
    "    model.eval()\n",
    "    batch_X, batch_y = batch_X.to(\"cuda\"), batch_y.to(\"cuda\")\n",
    "    pred = model(batch_X)\n",
    "\n",
    "    loss = torch.sqrt(criterion(pred, batch_y))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f99c30-ea3e-47a0-b925-838548581fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 1.5460 val_loss0.9454\n",
      "Epoch 2 train loss: 1.2571 val_loss0.9316\n",
      "Epoch 3 train loss: 1.2179 val_loss0.9052\n",
      "Epoch 4 train loss: 1.1988 val_loss0.8949\n",
      "Epoch 5 train loss: 1.1894 val_loss0.8952\n",
      "Epoch 6 train loss: 1.1859 val_loss0.8976\n",
      "Epoch 7 train loss: 1.1811 val_loss0.9028\n",
      "Epoch 8 train loss: 1.1768 val_loss0.8982\n",
      "Epoch 9 train loss: 1.1733 val_loss0.9085\n",
      "Epoch 10 train loss: 1.1727 val_loss0.8936\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# 10エポックで動作確認\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    val_loss = 0.\n",
    "\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        loss = train(batch_X, batch_y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    for batch_X, batch_y in val_dataloader:\n",
    "        loss = validation(batch_X, batch_y)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} train loss: {train_loss:.4f} val_loss{val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32874584-7501-4169-ad9a-4a9fb6d98ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-30 09:15:00,384]\u001b[0m A new study created in memory with name: no-name-816200c0-0f49-4634-a6cf-ccce6723a9f7\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:15:33,649]\u001b[0m Trial 0 finished with value: 0.9103587136076864 and parameters: {'dr': 0.3175997178494554, 'hidden_dim': 256}. Best is trial 0 with value: 0.9103587136076864.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:16:06,729]\u001b[0m Trial 1 finished with value: 0.8991878704102927 and parameters: {'dr': 0.12216728063565588, 'hidden_dim': 32}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:16:39,628]\u001b[0m Trial 2 finished with value: 0.908492523772541 and parameters: {'dr': 0.4359539731182841, 'hidden_dim': 512}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:17:12,406]\u001b[0m Trial 3 finished with value: 0.9050807212154532 and parameters: {'dr': 0.4957530594309756, 'hidden_dim': 256}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:17:45,938]\u001b[0m Trial 4 finished with value: 0.9038151067992052 and parameters: {'dr': 0.46029989631806445, 'hidden_dim': 128}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:18:19,069]\u001b[0m Trial 5 finished with value: 0.9062277999554955 and parameters: {'dr': 0.4070156872513182, 'hidden_dim': 64}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:18:51,830]\u001b[0m Trial 6 finished with value: 0.9060126692923003 and parameters: {'dr': 0.37152851730014713, 'hidden_dim': 32}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:19:24,670]\u001b[0m Trial 7 finished with value: 0.9059015881818856 and parameters: {'dr': 0.13470868788321885, 'hidden_dim': 32}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:19:57,268]\u001b[0m Trial 8 finished with value: 0.9044531122600847 and parameters: {'dr': 0.22540395223246787, 'hidden_dim': 64}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 09:20:30,007]\u001b[0m Trial 9 finished with value: 0.9047956194930761 and parameters: {'dr': 0.12109632061458916, 'hidden_dim': 32}. Best is trial 1 with value: 0.8991878704102927.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 隠れ層のユニット数，ドロップアウトの割合を最適化の対象にする\n",
    "def objective(trial):\n",
    "    dr = trial.suggest_float(\"dr\", 0.1, 0.6)\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [2**(i+5) for i in range(5)])\n",
    "\n",
    "    model = TestModel(len(features), hidden_dim, 1, dr=dr).to(\"cuda\")\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optimizers.Adam(model.parameters())\n",
    "\n",
    "    epochs = 30\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.\n",
    "\n",
    "        for batch_X, batch_y in train_dataloader:\n",
    "            loss = train(batch_X, batch_y)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        for batch_X, batch_y in val_dataloader:\n",
    "            loss = validation(batch_X, batch_y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "    val_loss = 0.\n",
    "    for batch_X, batch_y in val_dataloader:\n",
    "        loss = validation(batch_X, batch_y)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, 10, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f97c38-39ba-4986-8f27-bb63d91ffd06",
   "metadata": {},
   "source": [
    "## LightGBMの最適化\n",
    "LightGBMの最適化の場合は，目的関数を定義する必要はなくlightgbm用の最適化関数が用意されています．これを用いることでLightGBMの場合は簡単に最適化することができます．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7871427c-a36b-4538-9a61-81fcf7d1d2a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-30 09:26:43,447]\u001b[0m A new study created in memory with name: no-name-caab7f04-a1aa-4ff6-b163-087647e05c95\u001b[0m\n",
      "feature_fraction, val_score: inf:   0% 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.195144:  14% 1/7 [00:00<00:02,  2.63it/s]\u001b[32m[I 2022-05-30 09:26:43,829]\u001b[0m Trial 0 finished with value: 0.19514379281511343 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.19514379281511343.\u001b[0m\n",
      "feature_fraction, val_score: 0.195144:  14% 1/7 [00:00<00:02,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.193633:  29% 2/7 [00:00<00:01,  2.53it/s]\u001b[32m[I 2022-05-30 09:26:44,234]\u001b[0m Trial 1 finished with value: 0.19363338573467703 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.19363338573467703.\u001b[0m\n",
      "feature_fraction, val_score: 0.193633:  29% 2/7 [00:00<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.193314:  43% 3/7 [00:01<00:01,  2.42it/s]\u001b[32m[I 2022-05-30 09:26:44,670]\u001b[0m Trial 2 finished with value: 0.19331401247246432 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.19331401247246432.\u001b[0m\n",
      "feature_fraction, val_score: 0.193314:  43% 3/7 [00:01<00:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.193314:  57% 4/7 [00:01<00:01,  2.36it/s]\u001b[32m[I 2022-05-30 09:26:45,111]\u001b[0m Trial 3 finished with value: 0.19716473799039477 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.19331401247246432.\u001b[0m\n",
      "feature_fraction, val_score: 0.193314:  57% 4/7 [00:01<00:01,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.193314:  71% 5/7 [00:02<00:00,  2.45it/s]\u001b[32m[I 2022-05-30 09:26:45,490]\u001b[0m Trial 4 finished with value: 0.1997084522036733 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.19331401247246432.\u001b[0m\n",
      "feature_fraction, val_score: 0.193314:  71% 5/7 [00:02<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.193314:  86% 6/7 [00:02<00:00,  2.38it/s]\u001b[32m[I 2022-05-30 09:26:45,932]\u001b[0m Trial 5 finished with value: 0.1975975653988821 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.19331401247246432.\u001b[0m\n",
      "feature_fraction, val_score: 0.193314:  86% 6/7 [00:02<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.193314: 100% 7/7 [00:02<00:00,  2.46it/s]\u001b[32m[I 2022-05-30 09:26:46,310]\u001b[0m Trial 6 finished with value: 0.19514379281511343 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.19331401247246432.\u001b[0m\n",
      "feature_fraction, val_score: 0.193314: 100% 7/7 [00:02<00:00,  2.45it/s]\n",
      "num_leaves, val_score: 0.193314:   0% 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.193314:   5% 1/20 [00:01<00:23,  1.24s/it]\u001b[32m[I 2022-05-30 09:26:47,555]\u001b[0m Trial 7 finished with value: 0.2000215638573158 and parameters: {'num_leaves': 152}. Best is trial 7 with value: 0.2000215638573158.\u001b[0m\n",
      "num_leaves, val_score: 0.193314:   5% 1/20 [00:01<00:23,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.193314:  10% 2/20 [00:02<00:17,  1.02it/s]\u001b[32m[I 2022-05-30 09:26:48,347]\u001b[0m Trial 8 finished with value: 0.20045726120527274 and parameters: {'num_leaves': 90}. Best is trial 7 with value: 0.2000215638573158.\u001b[0m\n",
      "num_leaves, val_score: 0.193314:  10% 2/20 [00:02<00:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  15% 3/20 [00:02<00:12,  1.35it/s]\u001b[32m[I 2022-05-30 09:26:48,811]\u001b[0m Trial 9 finished with value: 0.1928880345156916 and parameters: {'num_leaves': 42}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  15% 3/20 [00:02<00:12,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  20% 4/20 [00:03<00:13,  1.22it/s]\u001b[32m[I 2022-05-30 09:26:49,745]\u001b[0m Trial 10 finished with value: 0.2014026484631612 and parameters: {'num_leaves': 109}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  20% 4/20 [00:03<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  25% 5/20 [00:04<00:13,  1.14it/s]\u001b[32m[I 2022-05-30 09:26:50,724]\u001b[0m Trial 11 finished with value: 0.20276920903566842 and parameters: {'num_leaves': 117}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  25% 5/20 [00:04<00:13,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  30% 6/20 [00:05<00:15,  1.10s/it]\u001b[32m[I 2022-05-30 09:26:52,271]\u001b[0m Trial 12 finished with value: 0.2046533879154493 and parameters: {'num_leaves': 193}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  30% 6/20 [00:05<00:15,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  35% 7/20 [00:07<00:14,  1.11s/it]\u001b[32m[I 2022-05-30 09:26:53,380]\u001b[0m Trial 13 finished with value: 0.19976796977633454 and parameters: {'num_leaves': 134}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  35% 7/20 [00:07<00:14,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  40% 8/20 [00:07<00:12,  1.04s/it]\u001b[32m[I 2022-05-30 09:26:54,270]\u001b[0m Trial 14 finished with value: 0.20136957516581167 and parameters: {'num_leaves': 104}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  40% 8/20 [00:07<00:12,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  45% 9/20 [00:09<00:12,  1.10s/it]\u001b[32m[I 2022-05-30 09:26:55,506]\u001b[0m Trial 15 finished with value: 0.2016348983434904 and parameters: {'num_leaves': 151}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  45% 9/20 [00:09<00:12,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  50% 10/20 [00:09<00:09,  1.08it/s]\u001b[32m[I 2022-05-30 09:26:56,048]\u001b[0m Trial 16 finished with value: 0.19958397489819027 and parameters: {'num_leaves': 53}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  55% 11/20 [00:09<00:06,  1.43it/s]\u001b[32m[I 2022-05-30 09:26:56,234]\u001b[0m Trial 17 finished with value: 0.21554339682784784 and parameters: {'num_leaves': 6}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  55% 11/20 [00:09<00:06,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  60% 12/20 [00:10<00:04,  1.66it/s]\u001b[32m[I 2022-05-30 09:26:56,616]\u001b[0m Trial 18 finished with value: 0.19422245626138598 and parameters: {'num_leaves': 32}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  65% 13/20 [00:10<00:03,  2.12it/s]\u001b[32m[I 2022-05-30 09:26:56,784]\u001b[0m Trial 19 finished with value: 0.22285928356173734 and parameters: {'num_leaves': 5}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  65% 13/20 [00:10<00:03,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  70% 14/20 [00:10<00:02,  2.06it/s]\u001b[32m[I 2022-05-30 09:26:57,305]\u001b[0m Trial 20 finished with value: 0.1975274895634369 and parameters: {'num_leaves': 51}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  70% 14/20 [00:10<00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  75% 15/20 [00:12<00:04,  1.08it/s]\u001b[32m[I 2022-05-30 09:26:59,250]\u001b[0m Trial 21 finished with value: 0.20930104299859525 and parameters: {'num_leaves': 245}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  75% 15/20 [00:12<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  80% 16/20 [00:13<00:03,  1.24it/s]\u001b[32m[I 2022-05-30 09:26:59,772]\u001b[0m Trial 22 finished with value: 0.19752748956343694 and parameters: {'num_leaves': 51}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  80% 16/20 [00:13<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  85% 17/20 [00:14<00:02,  1.31it/s]\u001b[32m[I 2022-05-30 09:27:00,440]\u001b[0m Trial 23 finished with value: 0.19821462434821663 and parameters: {'num_leaves': 70}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  85% 17/20 [00:14<00:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  90% 18/20 [00:14<00:01,  1.54it/s]\u001b[32m[I 2022-05-30 09:27:00,817]\u001b[0m Trial 24 finished with value: 0.19331401247246432 and parameters: {'num_leaves': 31}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  90% 18/20 [00:14<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888:  95% 19/20 [00:14<00:00,  1.80it/s]\u001b[32m[I 2022-05-30 09:27:01,156]\u001b[0m Trial 25 finished with value: 0.1985220494072273 and parameters: {'num_leaves': 26}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888:  95% 19/20 [00:14<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.192888: 100% 20/20 [00:15<00:00,  1.65it/s]\u001b[32m[I 2022-05-30 09:27:01,878]\u001b[0m Trial 26 finished with value: 0.1970324374388155 and parameters: {'num_leaves': 80}. Best is trial 9 with value: 0.1928880345156916.\u001b[0m\n",
      "num_leaves, val_score: 0.192888: 100% 20/20 [00:15<00:00,  1.28it/s]\n",
      "bagging, val_score: 0.192888:   0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  10% 1/10 [00:00<00:04,  1.92it/s]\u001b[32m[I 2022-05-30 09:27:02,404]\u001b[0m Trial 27 finished with value: 0.2045005684847451 and parameters: {'bagging_fraction': 0.7457523852417376, 'bagging_freq': 1}. Best is trial 27 with value: 0.2045005684847451.\u001b[0m\n",
      "bagging, val_score: 0.192888:  10% 1/10 [00:00<00:04,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  20% 2/10 [00:01<00:04,  1.96it/s]\u001b[32m[I 2022-05-30 09:27:02,904]\u001b[0m Trial 28 finished with value: 0.20005823991596489 and parameters: {'bagging_fraction': 0.8861149448577681, 'bagging_freq': 6}. Best is trial 28 with value: 0.20005823991596489.\u001b[0m\n",
      "bagging, val_score: 0.192888:  20% 2/10 [00:01<00:04,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  30% 3/10 [00:01<00:03,  1.96it/s]\u001b[32m[I 2022-05-30 09:27:03,413]\u001b[0m Trial 29 finished with value: 0.2033513097484264 and parameters: {'bagging_fraction': 0.7275289344214515, 'bagging_freq': 4}. Best is trial 28 with value: 0.20005823991596489.\u001b[0m\n",
      "bagging, val_score: 0.192888:  30% 3/10 [00:01<00:03,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  40% 4/10 [00:02<00:03,  1.94it/s]\u001b[32m[I 2022-05-30 09:27:03,941]\u001b[0m Trial 30 finished with value: 0.20081452564530958 and parameters: {'bagging_fraction': 0.7731010278512073, 'bagging_freq': 2}. Best is trial 28 with value: 0.20005823991596489.\u001b[0m\n",
      "bagging, val_score: 0.192888:  40% 4/10 [00:02<00:03,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  50% 5/10 [00:02<00:02,  1.93it/s]\u001b[32m[I 2022-05-30 09:27:04,462]\u001b[0m Trial 31 finished with value: 0.1957717775423214 and parameters: {'bagging_fraction': 0.8899113874259137, 'bagging_freq': 3}. Best is trial 31 with value: 0.1957717775423214.\u001b[0m\n",
      "bagging, val_score: 0.192888:  50% 5/10 [00:02<00:02,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  60% 6/10 [00:03<00:02,  1.93it/s]\u001b[32m[I 2022-05-30 09:27:04,982]\u001b[0m Trial 32 finished with value: 0.21392361164835336 and parameters: {'bagging_fraction': 0.5085370319340923, 'bagging_freq': 4}. Best is trial 31 with value: 0.1957717775423214.\u001b[0m\n",
      "bagging, val_score: 0.192888:  60% 6/10 [00:03<00:02,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  70% 7/10 [00:03<00:01,  1.93it/s]\u001b[32m[I 2022-05-30 09:27:05,496]\u001b[0m Trial 33 finished with value: 0.20001520034763035 and parameters: {'bagging_fraction': 0.8244754470863049, 'bagging_freq': 3}. Best is trial 31 with value: 0.1957717775423214.\u001b[0m\n",
      "bagging, val_score: 0.192888:  70% 7/10 [00:03<00:01,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  80% 8/10 [00:04<00:01,  1.94it/s]\u001b[32m[I 2022-05-30 09:27:06,009]\u001b[0m Trial 34 finished with value: 0.21605663826984842 and parameters: {'bagging_fraction': 0.5283492891334802, 'bagging_freq': 5}. Best is trial 31 with value: 0.1957717775423214.\u001b[0m\n",
      "bagging, val_score: 0.192888:  80% 8/10 [00:04<00:01,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888:  90% 9/10 [00:04<00:00,  1.96it/s]\u001b[32m[I 2022-05-30 09:27:06,510]\u001b[0m Trial 35 finished with value: 0.20121067820307403 and parameters: {'bagging_fraction': 0.8077240304135489, 'bagging_freq': 7}. Best is trial 31 with value: 0.1957717775423214.\u001b[0m\n",
      "bagging, val_score: 0.192888:  90% 9/10 [00:04<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.192888: 100% 10/10 [00:05<00:00,  1.95it/s]\u001b[32m[I 2022-05-30 09:27:07,028]\u001b[0m Trial 36 finished with value: 0.21077640550957208 and parameters: {'bagging_fraction': 0.5259332870012493, 'bagging_freq': 6}. Best is trial 31 with value: 0.1957717775423214.\u001b[0m\n",
      "bagging, val_score: 0.192888: 100% 10/10 [00:05<00:00,  1.94it/s]\n",
      "feature_fraction_stage2, val_score: 0.192888:   0% 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.192888:  17% 1/6 [00:00<00:02,  2.21it/s]\u001b[32m[I 2022-05-30 09:27:07,484]\u001b[0m Trial 37 finished with value: 0.19711835150671553 and parameters: {'feature_fraction': 0.552}. Best is trial 37 with value: 0.19711835150671553.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.192888:  17% 1/6 [00:00<00:02,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.192888:  33% 2/6 [00:00<00:01,  2.14it/s]\u001b[32m[I 2022-05-30 09:27:07,960]\u001b[0m Trial 38 finished with value: 0.1928880345156916 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 38 with value: 0.1928880345156916.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.192888:  33% 2/6 [00:00<00:01,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.192888:  50% 3/6 [00:01<00:01,  2.18it/s]\u001b[32m[I 2022-05-30 09:27:08,411]\u001b[0m Trial 39 finished with value: 0.19711835150671553 and parameters: {'feature_fraction': 0.52}. Best is trial 38 with value: 0.1928880345156916.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.192888:  50% 3/6 [00:01<00:01,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.192888:  67% 4/6 [00:01<00:00,  2.19it/s]\u001b[32m[I 2022-05-30 09:27:08,863]\u001b[0m Trial 40 finished with value: 0.1928880345156916 and parameters: {'feature_fraction': 0.584}. Best is trial 38 with value: 0.1928880345156916.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.192888:  67% 4/6 [00:01<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.192888:  83% 5/6 [00:02<00:00,  2.20it/s]\u001b[32m[I 2022-05-30 09:27:09,316]\u001b[0m Trial 41 finished with value: 0.1928880345156916 and parameters: {'feature_fraction': 0.616}. Best is trial 38 with value: 0.1928880345156916.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.192888:  83% 5/6 [00:02<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.192888: 100% 6/6 [00:02<00:00,  2.20it/s]\u001b[32m[I 2022-05-30 09:27:09,770]\u001b[0m Trial 42 finished with value: 0.1928880345156916 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 38 with value: 0.1928880345156916.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.192888: 100% 6/6 [00:02<00:00,  2.19it/s]\n",
      "regularization_factors, val_score: 0.192888:   0% 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:   5% 1/20 [00:00<00:09,  2.02it/s]\u001b[32m[I 2022-05-30 09:27:10,268]\u001b[0m Trial 43 finished with value: 0.19594175327324873 and parameters: {'lambda_l1': 0.4034896553328801, 'lambda_l2': 0.10058701590260577}. Best is trial 43 with value: 0.19594175327324873.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:   5% 1/20 [00:00<00:09,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  10% 2/20 [00:00<00:08,  2.06it/s]\u001b[32m[I 2022-05-30 09:27:10,746]\u001b[0m Trial 44 finished with value: 0.19465357238256123 and parameters: {'lambda_l1': 1.7751775365759052e-05, 'lambda_l2': 2.2180451075291145}. Best is trial 44 with value: 0.19465357238256123.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  10% 2/20 [00:00<00:08,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  15% 3/20 [00:01<00:08,  2.04it/s]\u001b[32m[I 2022-05-30 09:27:11,244]\u001b[0m Trial 45 finished with value: 0.1936264690292204 and parameters: {'lambda_l1': 0.11403942435943695, 'lambda_l2': 9.919135581531181}. Best is trial 45 with value: 0.1936264690292204.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  15% 3/20 [00:01<00:08,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  20% 4/20 [00:01<00:07,  2.06it/s]\u001b[32m[I 2022-05-30 09:27:11,720]\u001b[0m Trial 46 finished with value: 0.19431586512091878 and parameters: {'lambda_l1': 0.01201307295676159, 'lambda_l2': 0.4736806314269514}. Best is trial 45 with value: 0.1936264690292204.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  20% 4/20 [00:01<00:07,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  25% 5/20 [00:02<00:07,  2.08it/s]\u001b[32m[I 2022-05-30 09:27:12,193]\u001b[0m Trial 47 finished with value: 0.19490464591634124 and parameters: {'lambda_l1': 5.363819239369485e-06, 'lambda_l2': 0.0007016198260140484}. Best is trial 45 with value: 0.1936264690292204.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  25% 5/20 [00:02<00:07,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  30% 6/20 [00:02<00:06,  2.22it/s]\u001b[32m[I 2022-05-30 09:27:12,583]\u001b[0m Trial 48 finished with value: 0.19873687626722839 and parameters: {'lambda_l1': 9.46245407441294, 'lambda_l2': 4.060723775375909e-08}. Best is trial 45 with value: 0.1936264690292204.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  30% 6/20 [00:02<00:06,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  35% 7/20 [00:03<00:05,  2.19it/s]\u001b[32m[I 2022-05-30 09:27:13,053]\u001b[0m Trial 49 finished with value: 0.1928880221803467 and parameters: {'lambda_l1': 3.886576368423466e-06, 'lambda_l2': 2.149962254429857e-05}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  35% 7/20 [00:03<00:05,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  40% 8/20 [00:03<00:05,  2.17it/s]\u001b[32m[I 2022-05-30 09:27:13,521]\u001b[0m Trial 50 finished with value: 0.19468995046481757 and parameters: {'lambda_l1': 9.124342450287878e-07, 'lambda_l2': 0.010849339704482864}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  40% 8/20 [00:03<00:05,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  45% 9/20 [00:04<00:05,  2.14it/s]\u001b[32m[I 2022-05-30 09:27:14,008]\u001b[0m Trial 51 finished with value: 0.19763883221632111 and parameters: {'lambda_l1': 0.0010416409903748023, 'lambda_l2': 1.039394036607277}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  45% 9/20 [00:04<00:05,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  50% 10/20 [00:04<00:04,  2.04it/s]\u001b[32m[I 2022-05-30 09:27:14,550]\u001b[0m Trial 52 finished with value: 0.1938290044676965 and parameters: {'lambda_l1': 1.6935332635049347, 'lambda_l2': 8.681574924208297}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  50% 10/20 [00:04<00:04,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  55% 11/20 [00:05<00:04,  2.06it/s]\u001b[32m[I 2022-05-30 09:27:15,026]\u001b[0m Trial 53 finished with value: 0.19288803407360397 and parameters: {'lambda_l1': 1.4614495417792556e-08, 'lambda_l2': 1.6570539038210203e-06}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  55% 11/20 [00:05<00:04,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  60% 12/20 [00:05<00:03,  2.07it/s]\u001b[32m[I 2022-05-30 09:27:15,501]\u001b[0m Trial 54 finished with value: 0.19288803417974204 and parameters: {'lambda_l1': 1.2141323608254832e-08, 'lambda_l2': 1.2440605870533948e-06}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  60% 12/20 [00:05<00:03,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  65% 13/20 [00:06<00:03,  2.08it/s]\u001b[32m[I 2022-05-30 09:27:15,978]\u001b[0m Trial 55 finished with value: 0.1928880325382327 and parameters: {'lambda_l1': 1.107463603757339e-08, 'lambda_l2': 7.90565020749148e-06}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  65% 13/20 [00:06<00:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  70% 14/20 [00:06<00:02,  2.09it/s]\u001b[32m[I 2022-05-30 09:27:16,453]\u001b[0m Trial 56 finished with value: 0.1928880269828334 and parameters: {'lambda_l1': 3.1359399467519604e-07, 'lambda_l2': 2.897263161286886e-05}. Best is trial 49 with value: 0.1928880221803467.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  70% 14/20 [00:06<00:02,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  75% 15/20 [00:07<00:02,  2.09it/s]\u001b[32m[I 2022-05-30 09:27:16,927]\u001b[0m Trial 57 finished with value: 0.19288801826255725 and parameters: {'lambda_l1': 4.049491749517955e-07, 'lambda_l2': 6.504594085658554e-05}. Best is trial 57 with value: 0.19288801826255725.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  75% 15/20 [00:07<00:02,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  80% 16/20 [00:07<00:01,  2.09it/s]\u001b[32m[I 2022-05-30 09:27:17,409]\u001b[0m Trial 58 finished with value: 0.19468815957954747 and parameters: {'lambda_l1': 7.682761723066561e-05, 'lambda_l2': 0.00032387425081446743}. Best is trial 57 with value: 0.19288801826255725.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  80% 16/20 [00:07<00:01,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  85% 17/20 [00:08<00:01,  2.09it/s]\u001b[32m[I 2022-05-30 09:27:17,885]\u001b[0m Trial 59 finished with value: 0.19288803370855126 and parameters: {'lambda_l1': 4.3187910275339054e-07, 'lambda_l2': 2.995719180884099e-08}. Best is trial 57 with value: 0.19288801826255725.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  85% 17/20 [00:08<00:01,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  90% 18/20 [00:08<00:00,  2.09it/s]\u001b[32m[I 2022-05-30 09:27:18,367]\u001b[0m Trial 60 finished with value: 0.19469667282882452 and parameters: {'lambda_l1': 0.0006333275205276706, 'lambda_l2': 0.006319864092875368}. Best is trial 57 with value: 0.19288801826255725.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  90% 18/20 [00:08<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888:  95% 19/20 [00:09<00:00,  2.09it/s]\u001b[32m[I 2022-05-30 09:27:18,846]\u001b[0m Trial 61 finished with value: 0.19288801372484476 and parameters: {'lambda_l1': 2.70997039083449e-06, 'lambda_l2': 6.593468266917905e-05}. Best is trial 61 with value: 0.19288801372484476.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888:  95% 19/20 [00:09<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.192888: 100% 20/20 [00:09<00:00,  2.08it/s]\u001b[32m[I 2022-05-30 09:27:19,327]\u001b[0m Trial 62 finished with value: 0.19436904180269504 and parameters: {'lambda_l1': 1.6577793031719746e-07, 'lambda_l2': 0.0031503762094517935}. Best is trial 61 with value: 0.19288801372484476.\u001b[0m\n",
      "regularization_factors, val_score: 0.192888: 100% 20/20 [00:09<00:00,  2.09it/s]\n",
      "min_data_in_leaf, val_score: 0.192888:   0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.192888:  20% 1/5 [00:00<00:01,  2.01it/s]\u001b[32m[I 2022-05-30 09:27:19,827]\u001b[0m Trial 63 finished with value: 0.19863499390414713 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.19863499390414713.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.192888:  20% 1/5 [00:00<00:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.192888:  40% 2/5 [00:01<00:01,  1.85it/s]\u001b[32m[I 2022-05-30 09:27:20,400]\u001b[0m Trial 64 finished with value: 0.20003791902259982 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.19863499390414713.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.192888:  40% 2/5 [00:01<00:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.192888:  60% 3/5 [00:01<00:01,  1.93it/s]\u001b[32m[I 2022-05-30 09:27:20,888]\u001b[0m Trial 65 finished with value: 0.1954040203758196 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.1954040203758196.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.192888:  60% 3/5 [00:01<00:01,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.192888:  80% 4/5 [00:02<00:00,  1.99it/s]\u001b[32m[I 2022-05-30 09:27:21,366]\u001b[0m Trial 66 finished with value: 0.19572303008710432 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 0.1954040203758196.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.192888:  80% 4/5 [00:02<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.066357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.192888: 100% 5/5 [00:02<00:00,  2.02it/s]\u001b[32m[I 2022-05-30 09:27:21,850]\u001b[0m Trial 67 finished with value: 0.19825709477162398 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.1954040203758196.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.192888: 100% 5/5 [00:02<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=6174)\n",
    "\n",
    "lgb_train = lgb.Dataset(train_X, train_y)\n",
    "lgb_val = lgb.Dataset(val_X, val_y)\n",
    "\n",
    "# lightgbmの最低限設定したいパラメータ\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mean_squared_error\",\n",
    "}\n",
    "\n",
    "# モデルの学習\n",
    "model = lgbo.train(params, lgb_train, valid_sets=lgb_val,\n",
    "                   verbose_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d703f-7b8c-4a4b-afff-546f7bf43212",
   "metadata": {},
   "source": [
    "最適化後のモデルのパラメータはparams属性にアクセスすることで得ることができます．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da0a8022-64a2-499f-9a2f-fe88c4896e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression',\n",
       " 'metric': 'l2',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 2.70997039083449e-06,\n",
       " 'lambda_l2': 6.593468266917905e-05,\n",
       " 'num_leaves': 42,\n",
       " 'feature_fraction': 0.6,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ceb7c-7ed0-4544-91c6-6bb0425af09c",
   "metadata": {},
   "source": [
    "また訓練したときのモデルをそのまま用いて予測をすることも可能です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ee0af14-b6a6-422d-9dd7-326dfb8ab3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.39485911])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(val_X[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265533c6-8929-42ac-8d40-fcb91a1626d1",
   "metadata": {},
   "source": [
    "Optuna: https://optuna.readthedocs.io/en/stable/index.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fb52a-5401-4f2b-9e18-31bc8358f582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
